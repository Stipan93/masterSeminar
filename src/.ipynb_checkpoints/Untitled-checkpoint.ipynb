{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-81de8d108ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransform_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_all_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, precision_score, f1_score\n",
    "\n",
    "from src.preprocessing import transform_train_features, transform_test_features, transform_all_features\n",
    "from src.utils import get_data, Dataset\n",
    "from src.feature_extraction import get_features\n",
    "\n",
    "\n",
    "def current_milli_time():\n",
    "    return int(round(time.time() * 1000))\n",
    "\n",
    "\n",
    "def print_ms(message, t1, t2):\n",
    "    print(message, t2-t1, 'ms')\n",
    "\n",
    "\n",
    "def print_help(parser, message):\n",
    "    parser.print_help()\n",
    "    print(message)\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "def check_argument_set(arg_set, choices, parser):\n",
    "    for arg in arg_set:\n",
    "        if arg not in choices:\n",
    "            print_help(parser, \"'\"+arg+\"' is not in possible choices: \"+str(choices))\n",
    "\n",
    "\n",
    "def get_set(_set, languages):\n",
    "    dataset = Dataset()\n",
    "    for lang in languages:\n",
    "        data = get_data(lang)\n",
    "        dataset.merge(data.get_set(_set))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_serialized_sets(_set, languages):\n",
    "    dataset = Dataset()\n",
    "    for lang in languages:\n",
    "        with open('../serialization/' + _set + '.' + lang, 'rb') as handle:\n",
    "            train = pickle.load(handle)\n",
    "            dataset.merge(train)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_data(train, name1, validation, name2, test, name3):\n",
    "    with open('../serialization/'+name1, 'wb') as handle:\n",
    "        pickle.dump(train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('../serialization/'+name2, 'wb') as handle:\n",
    "        pickle.dump(validation, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('../serialization/'+name3, 'wb') as handle:\n",
    "        pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_data(name1, name2, name3):\n",
    "    with open('../serialization/'+name1, 'rb') as handle:\n",
    "        train = pickle.load(handle)\n",
    "    with open('../serialization/' + name2, 'rb') as handle:\n",
    "        validation = pickle.load(handle)\n",
    "    with open('../serialization/'+name3, 'rb') as handle:\n",
    "        test = pickle.load(handle)\n",
    "    return train, validation, test\n",
    "\n",
    "\n",
    "def parse_arguments(args):\n",
    "    choices = ['eng', 'esp', 'ned']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-train')\n",
    "    parser.add_argument('-validation')\n",
    "    parser.add_argument('-test')\n",
    "\n",
    "    parsed_args = parser.parse_args(args[1:])\n",
    "    if None in [parsed_args.train, parsed_args.test]:\n",
    "        print_help(parser, 'Must provide both train and test sets.')\n",
    "\n",
    "    train_sets = parsed_args.train.split(',')\n",
    "    validation_sets = parsed_args.validation.split(',')\n",
    "    test_sets = parsed_args.test.split(',')\n",
    "\n",
    "    print('checking arguments')\n",
    "    check_argument_set(train_sets, choices, parser)\n",
    "    check_argument_set(validation_sets, choices, parser)\n",
    "    check_argument_set(test_sets, choices, parser)\n",
    "    return train_sets, validation_sets, test_sets\n",
    "\n",
    "\n",
    "def get_datasets(train_sets, validation_sets, test_sets):\n",
    "    print('loading train, validation and test set')\n",
    "    t0 = current_milli_time()\n",
    "    train = get_serialized_sets('train', train_sets)\n",
    "    validation = get_serialized_sets('validation', validation_sets)\n",
    "    test = get_serialized_sets('test', test_sets)\n",
    "    # train = get_set('train', train_sets)\n",
    "    # validation = get_set('validation', validation_sets)\n",
    "    # test = get_set('test', test_sets)\n",
    "    # train, validation, test = load_data('train.'+parsed_args.train, 'validation.'+parsed_args.validation,\n",
    "    #                                     'test.'+parsed_args.test)\n",
    "    print_ms('data loaded in: ', t0, current_milli_time())\n",
    "\n",
    "    # save_data(train, 'train.'+parsed_args.train, validation, 'validation.'+parsed_args.validation,\n",
    "    #           test, 'test.'+parsed_args.test)\n",
    "    return train, validation, test\n",
    "\n",
    "\n",
    "def get_all_features(train, validation, test):\n",
    "    t1 = current_milli_time()\n",
    "    print('\\ngetting train features')\n",
    "    train_features, train_y = get_features(train)\n",
    "    t2 = current_milli_time()\n",
    "    print_ms('train features: ', t1, t2)\n",
    "\n",
    "    print('\\ngetting validation features')\n",
    "    validation_features, validation_y = get_features(validation)\n",
    "    t3 = current_milli_time()\n",
    "    print_ms('validation features: ', t2, t3)\n",
    "\n",
    "    print('\\ngetting test features')\n",
    "    test_features, test_y = get_features(test)\n",
    "    t4 = current_milli_time()\n",
    "    print_ms('test features: ', t3, t4)\n",
    "    return train_features, train_y, validation_features, validation_y, test_features, test_y\n",
    "\n",
    "\n",
    "\n",
    "def make_args(train, test):\n",
    "    return ['/home/stipan/dev/fer/seminar/src/baseline.py', '-train', train, '-validation', train, '-test', test]\n",
    "\n",
    "\n",
    "def all_combinations():\n",
    "    for i in ['eng', 'esp', 'ned']:\n",
    "        for j in ['eng', 'esp', 'ned']:\n",
    "            main(make_args(i, j))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # main(sys.argv)\n",
    "    all_combinations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = ['/home/stipan/dev/fer/seminar/src/baseline.py', '-train', 'eng', '-validation', 'eng', '-test', 'eng']\n",
    "train_sets, validation_sets, test_sets = parse_arguments(args)\n",
    "train, validation, test = get_datasets(train_sets, validation_sets, test_sets)\n",
    "train_features, train_y, validation_features, validation_y, test_features, test_y = \\\n",
    "    get_all_features(train, validation, test)\n",
    "\n",
    "print('\\ntransforming features')\n",
    "print(len(train_features))\n",
    "print(len(validation_features))\n",
    "print(len(test_features))\n",
    "print('###################')\n",
    "t5 = current_milli_time()\n",
    "train_features, validation_features, test_features, encoders = \\\n",
    "    transform_all_features(train_features, validation_features, test_features)\n",
    "print_ms('Features transform: ', t5, current_milli_time())\n",
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "print('\\ntraining model')\n",
    "\n",
    "t6 = current_milli_time()\n",
    "# lr = LogisticRegressionCV(class_weight='balanced', n_jobs=-1, max_iter=300000, multi_class='multinomial')\n",
    "# lr.fit(train_features, train_y)\n",
    "best_estimator = None\n",
    "max_f1_micro = None\n",
    "max_f1_macro = None\n",
    "for alpha in [10**i for i in range(-10, -1)]:\n",
    "    p = Perceptron(n_jobs=-1, alpha=alpha, penalty='l2', shuffle=True)\n",
    "    p.fit(train_features, train_y)\n",
    "\n",
    "    print_ms('\\ntraining done: ', t6, current_milli_time())\n",
    "    predicted_y = p.predict(validation_features)\n",
    "    temp_f1 = f1_score(validation_y, predicted_y, average='micro')\n",
    "    if max_f1_micro is None or max_f1_micro < temp_f1:\n",
    "        max_f1_micro = temp_f1\n",
    "        max_f1_macro = f1_score(validation_y, predicted_y, average='macro')\n",
    "        best_estimator = p\n",
    "    print(p.get_params())\n",
    "    print(classification_report(validation_y, predicted_y))\n",
    "    print(\"micro: \", precision_score(validation_y, predicted_y, average='micro'))\n",
    "    print(\"macro: \", precision_score(validation_y, predicted_y, average='macro'))\n",
    "    print(\"#\"*100)\n",
    "# print(len(train.documents))\n",
    "# print(len(validation.documents))\n",
    "# print(len(test.documents))\n",
    "a = np.hstack((train_features, validation_features))\n",
    "best_estimator.fit(a, train_y+validation_y)\n",
    "predicted_y = best_estimator.predict(test_features)\n",
    "print(classification_report(test_y, predicted_y))\n",
    "print(\"micro: \", precision_score(test_y, predicted_y, average='micro'))\n",
    "print(\"macro: \", precision_score(test_y, predicted_y, average='macro'))\n",
    "print(\"#\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
